FULL PROJECT EXPORT FOR AI ANALYSIS
Generated: 2026-02-11 14:22:44



////////////////////////////////////////////////////////////////
 * FILE PATH: ./.env
////////////////////////////////////////////////////////////////

DATABASE_URL=postgresql+psycopg2://gyaanchat:gyaanchat_password@127.0.0.1:5432/gyaanchat
JWT_SECRET=change_this_to_any_random_string
JWT_EXPIRE_MINUTES=10080


////////////////////////////////////////////////////////////////
 * FILE PATH: ./export.py
////////////////////////////////////////////////////////////////

import os
from datetime import datetime

OUTPUT_FILE = "ProjectContext.txt"

# Include these file types (add/remove as you like)
INCLUDE_EXTENSIONS = {
    ".py", ".txt", ".md", ".json", ".yaml", ".yml", ".ini", ".toml", ".env"
}

# Skip junk / generated / big dirs
EXCLUDE_DIRS = {
    "__pycache__", ".git", ".venv", "venv", "env", ".idea", ".vscode", "node_modules", "uploads"
}

# Skip big/irrelevant files by name (optional)
EXCLUDE_FILES = {
    OUTPUT_FILE,  # don't re-include the output itself
}

def should_skip_dir(name: str) -> bool:
    return name in EXCLUDE_DIRS

def should_include_file(filename: str) -> bool:
    if filename in EXCLUDE_FILES:
        return False
    ext = os.path.splitext(filename)[1].lower()
    return ext in INCLUDE_EXTENSIONS or filename.lower() in {".env"}

with open(OUTPUT_FILE, "w", encoding="utf-8") as out:
    out.write("FULL PROJECT EXPORT FOR AI ANALYSIS\n")
    out.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

    for root, dirs, files in os.walk("."):
        # prune excluded dirs so os.walk doesn't enter them
        dirs[:] = [d for d in dirs if not should_skip_dir(d)]

        for file in sorted(files):
            if not should_include_file(file):
                continue

            filepath = os.path.join(root, file)
            norm_path = filepath.replace("\\", "/")

            out.write("\n\n" + ("/" * 64) + "\n")
            out.write(f" * FILE PATH: {norm_path}\n")
            out.write(("/" * 64) + "\n\n")

            try:
                with open(filepath, "r", encoding="utf-8") as f:
                    out.write(f.read())
            except UnicodeDecodeError:
                out.write("[Skipped: non-UTF8/binary file]\n")
            except Exception as e:
                out.write(f"[Error reading file: {e}]\n")

print(f"✅ Exported project context to: {OUTPUT_FILE}")


////////////////////////////////////////////////////////////////
 * FILE PATH: ./requirements.txt
////////////////////////////////////////////////////////////////

sqlalchemy>=2.0
psycopg2-binary>=2.9
python-dotenv>=1.0
passlib[bcrypt]>=1.7
python-jose[cryptography]>=3.3


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/auth_utils.py
////////////////////////////////////////////////////////////////

import os
from datetime import datetime, timedelta
from dotenv import load_dotenv
from jose import jwt, JWTError

load_dotenv()

JWT_SECRET = os.getenv("JWT_SECRET", "dev_secret_change_me")
JWT_ALG = "HS256"
JWT_EXPIRE_MINUTES = int(os.getenv("JWT_EXPIRE_MINUTES", "10080"))  # 7 days

import bcrypt

def hash_password(password: str) -> str:
    # bcrypt expects bytes, and returns bytes
    pwd_bytes = password.encode('utf-8')
    salt = bcrypt.gensalt()
    hashed = bcrypt.hashpw(pwd_bytes, salt)
    return hashed.decode('utf-8')

def verify_password(password: str, password_hash: str) -> bool:
    pwd_bytes = password.encode('utf-8')
    hash_bytes = password_hash.encode('utf-8')
    return bcrypt.checkpw(pwd_bytes, hash_bytes)

def create_access_token(payload: dict) -> str:
    exp = datetime.utcnow() + timedelta(minutes=JWT_EXPIRE_MINUTES)
    to_encode = {**payload, "exp": exp}
    return jwt.encode(to_encode, JWT_SECRET, algorithm=JWT_ALG)

def decode_token(token: str) -> dict:
    try:
        return jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALG])
    except JWTError:
        raise ValueError("Invalid token")


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/db.py
////////////////////////////////////////////////////////////////

import os
from pathlib import Path
from dotenv import load_dotenv
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, DeclarativeBase

# Always load backend/.env explicitly
ENV_PATH = Path(__file__).resolve().parents[1] / ".env"  # backend/.env
load_dotenv(dotenv_path=ENV_PATH)

DATABASE_URL = os.getenv("DATABASE_URL")
print("USING DATABASE_URL =", DATABASE_URL)  # temporary debug

if not DATABASE_URL:
    raise RuntimeError(f"DATABASE_URL missing. Expected at: {ENV_PATH}")

engine = create_engine(DATABASE_URL, pool_pre_ping=True)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

class Base(DeclarativeBase):
    pass

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/main.py
////////////////////////////////////////////////////////////////

from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
# from .db import engine
# from .models import Base
# from .api.auth import router as auth_router
import os
# from app.api import documents, chat

app = FastAPI(title="GyaanChat AI")

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
@app.middleware("http")
async def log_requests(request, call_next):
    print(f"LOG: {request.method} {request.url}")
    return await call_next(request)

# Global configuration
RAG_DISTANCE_THRESHOLD = float(os.getenv("RAG_DISTANCE_THRESHOLD", "0.5"))

# app.include_router(auth_router)
# app.include_router(documents.router, prefix="/documents")
# app.include_router(chat.router, prefix="/chat")

@app.get("/")
def health_check():
    return {"status": "ok", "threshold": RAG_DISTANCE_THRESHOLD}

@app.on_event("startup")
def on_startup():
    Base.metadata.create_all(bind=engine)


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/models.py
////////////////////////////////////////////////////////////////

import uuid
from datetime import datetime
from sqlalchemy import String, DateTime, ForeignKey, Boolean, Text
from sqlalchemy.orm import Mapped, mapped_column, relationship
from .db import Base

def _uuid():
    return str(uuid.uuid4())

class Tenant(Base):
    __tablename__ = "tenants"

    id: Mapped[str] = mapped_column(String, primary_key=True, default=_uuid)
    name: Mapped[str] = mapped_column(String, nullable=False)
    is_active: Mapped[bool] = mapped_column(Boolean, default=True)

    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)

    users = relationship("User", back_populates="tenant")
    bots = relationship("Bot", back_populates="tenant")


class User(Base):
    __tablename__ = "users"

    id: Mapped[str] = mapped_column(String, primary_key=True, default=_uuid)
    tenant_id: Mapped[str] = mapped_column(String, ForeignKey("tenants.id"), nullable=False)

    name: Mapped[str] = mapped_column(String, nullable=False)
    email: Mapped[str] = mapped_column(String, unique=True, index=True, nullable=False)
    password_hash: Mapped[str] = mapped_column(String, nullable=False)

    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)

    tenant = relationship("Tenant", back_populates="users")


class Bot(Base):
    __tablename__ = "bots"

    id: Mapped[str] = mapped_column(String, primary_key=True, default=_uuid)
    tenant_id: Mapped[str] = mapped_column(String, ForeignKey("tenants.id"), nullable=False)

    name: Mapped[str] = mapped_column(String, default="GyaanChat Bot")
    greeting: Mapped[str] = mapped_column(Text, default="Hi! How can I help you?")
    fallback: Mapped[str] = mapped_column(Text, default="I couldn’t find that in your documents.")
    theme_color: Mapped[str] = mapped_column(String, default="#3b82f6")
    temperature: Mapped[str] = mapped_column(String, default="0.2")

    widget_key: Mapped[str] = mapped_column(String, unique=True, index=True, nullable=False, default=_uuid)

    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)

    tenant = relationship("Tenant", back_populates="bots")


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/requirements.txt
////////////////////////////////////////////////////////////////

python-multipart
PyPDF2


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/api/auth.py
////////////////////////////////////////////////////////////////

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel, EmailStr
from sqlalchemy.orm import Session

from ..db import get_db
from ..models import User, Tenant, Bot
from ..auth_utils import hash_password, verify_password, create_access_token

router = APIRouter(prefix="/auth", tags=["auth"])

class RegisterIn(BaseModel):
    name: str
    email: EmailStr
    password: str
    website_name: str  # tenant name

class LoginIn(BaseModel):
    email: EmailStr
    password: str

@router.post("/register")
def register(data: RegisterIn, db: Session = Depends(get_db)):
    print(f"ENTERED register: {data.email}")
    existing = db.query(User).filter(User.email == data.email).first()
    if existing:
        raise HTTPException(status_code=400, detail="Email already registered")

    tenant = Tenant(name=data.website_name)
    db.add(tenant)
    db.flush()  # get tenant.id

    user = User(
        tenant_id=tenant.id,
        name=data.name,
        email=data.email,
        password_hash=hash_password(data.password),
    )
    db.add(user)

    bot = Bot(tenant_id=tenant.id, name=f"{data.website_name} Bot")
    db.add(bot)

    db.commit()
    db.refresh(user)
    db.refresh(bot)

    token = create_access_token({"sub": user.id, "tenant_id": tenant.id})
    return {
        "token": token,
        "user": {"id": user.id, "name": user.name, "email": user.email},
        "tenant": {"id": tenant.id, "name": tenant.name},
        "bot": {"id": bot.id, "name": bot.name, "widget_key": bot.widget_key},
    }

@router.post("/login")
def login(data: LoginIn, db: Session = Depends(get_db)):
    user = db.query(User).filter(User.email == data.email).first()
    if not user or not verify_password(data.password, user.password_hash):
        raise HTTPException(status_code=401, detail="Invalid email or password")

    tenant = db.query(Tenant).filter(Tenant.id == user.tenant_id).first()
    if tenant and not tenant.is_active:
        raise HTTPException(status_code=403, detail="Tenant is suspended")

    bot = db.query(Bot).filter(Bot.tenant_id == user.tenant_id).first()

    token = create_access_token({"sub": user.id, "tenant_id": user.tenant_id})
    return {
        "token": token,
        "user": {"id": user.id, "name": user.name, "email": user.email},
        "tenant": {"id": user.tenant_id, "name": tenant.name if tenant else ""},
        "bot": {"id": bot.id if bot else None, "name": bot.name if bot else None, "widget_key": bot.widget_key if bot else None},
    }


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/api/chat.py
////////////////////////////////////////////////////////////////

from typing import Optional, List
from fastapi import APIRouter, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session

from ..db import get_db
from ..models import Bot

from app.services.llm import generate_answer
from app.services.embeddings import embed_texts
from app.services.vector_store import get_collection
from app.services.rag import build_prompt

router = APIRouter()

# Simple widget mapping: widget_key -> tenant_id
WIDGET_MAPPING = {
    "default_key": "test_tenant"
}

class ChatRequest(BaseModel):
    tenant_id: str
    question: str

class WidgetChatRequest(BaseModel):
    widget_key: str
    visitor_id: str
    message: str

@router.post("/")
def chat(req: ChatRequest):
    # Import threshold from main to keep it configurable
    from app.main import RAG_DISTANCE_THRESHOLD

    collection = get_collection(req.tenant_id)
    query_embedding = embed_texts([req.question])[0]

    # Request distances to implement threshold check
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=4
    )

    docs = results["documents"][0] if results["documents"] else []
    metadatas = results["metadatas"][0] if results["metadatas"] else []
    distances = results["distances"][0] if results["distances"] else []

    # Hallucination control: check if best distance is within threshold
    # Note: Chroma cosine distance: lower is more similar.
    is_relevant = False
    if distances and distances[0] < RAG_DISTANCE_THRESHOLD:
        is_relevant = True

    if not docs or not is_relevant:
        return {
            "answer": "I couldn’t find this information in the provided documents.",
            "used_sources": False,
            "sources": []
        }

    prompt = build_prompt(docs, req.question)
    answer = generate_answer(prompt)

    # Prepare sources (simplified as requested)
    sources = []
    if metadatas:
        for meta in metadatas:
            sources.append({
                "doc_id": meta.get("doc_id"),
                "chunk_index": meta.get("chunk_index"),
                "filename": meta.get("filename")
            })

    return {
        "answer": answer,
        "used_sources": True,
        "sources": sources
    }

@router.post("/widget")
def widget_chat(req: WidgetChatRequest, db: Session = Depends(get_db)):
    bot = db.query(Bot).filter(Bot.widget_key == req.widget_key).first()
    if not bot:
        return {
            "answer": "Invalid widget key.",
            "used_sources": False,
            "sources": []
        }
    
    tenant_id = bot.tenant_id
    # Reuse chat logic
    chat_req = ChatRequest(tenant_id=tenant_id, question=req.message)
    return chat(chat_req)


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/api/documents.py
////////////////////////////////////////////////////////////////

from fastapi import APIRouter, UploadFile, File, BackgroundTasks, HTTPException
import uuid
import os
import json
import time

from app.services.pdf_loader import extract_text_from_pdf
from app.services.chunker import chunk_text
from app.services.embeddings import embed_texts
from app.services.vector_store import get_collection

router = APIRouter()

UPLOAD_DIR = "uploads"
STATUS_DIR = os.path.join(UPLOAD_DIR, "status")
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(STATUS_DIR, exist_ok=True)

def update_status(doc_id: str, status: str, tenant_id: str, filename: str, error: str = None):
    status_path = os.path.join(STATUS_DIR, f"{doc_id}.json")
    status_data = {
        "doc_id": doc_id,
        "tenant_id": tenant_id,
        "filename": filename,
        "status": status,
        "updated_at": time.time(),
        "error": error
    }
    with open(status_path, "w") as f:
        json.dump(status_data, f)

def process_document_task(file_path: str, doc_id: str, tenant_id: str, filename: str, bot_id: str = "default"):
    try:
        update_status(doc_id, "processing", tenant_id, filename)
        
        text = extract_text_from_pdf(file_path)
        chunks = chunk_text(text)
        embeddings = embed_texts(chunks)

        collection = get_collection(tenant_id)

        ids = [f"{doc_id}_{i}" for i in range(len(chunks))]
        metadatas = [
            {
                "tenant_id": tenant_id,
                "doc_id": doc_id,
                "chunk_index": i,
                "filename": filename,
                "bot_id": bot_id
            } for i in range(len(chunks))
        ]

        collection.add(
            documents=chunks,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        
        update_status(doc_id, "ready", tenant_id, filename)
    except Exception as e:
        update_status(doc_id, "failed", tenant_id, filename, error=str(e))

@router.post("/upload")
async def upload_document(
    tenant_id: str,
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    bot_id: str = "default"
):
    if not file.filename.endswith(".pdf"):
        raise HTTPException(status_code=400, detail="Only PDF files are supported")

    doc_id = str(uuid.uuid4())
    file_path = os.path.join(UPLOAD_DIR, f"{doc_id}_{file.filename}")

    with open(file_path, "wb") as f:
        f.write(await file.read())

    # Initialize status
    update_status(doc_id, "uploaded", tenant_id, file.filename)

    # Add background task
    background_tasks.add_task(process_document_task, file_path, doc_id, tenant_id, file.filename, bot_id)

    return {
        "message": "Processing started",
        "doc_id": doc_id,
        "tenant_id": tenant_id
    }

@router.get("/status")
def get_doc_status(tenant_id: str, doc_id: str):
    status_path = os.path.join(STATUS_DIR, f"{doc_id}.json")
    if not os.path.exists(status_path):
        raise HTTPException(status_code=404, detail="Document status not found")
    
    with open(status_path, "r") as f:
        status_data = json.load(f)
    
    if status_data["tenant_id"] != tenant_id:
        raise HTTPException(status_code=403, detail="Unauthorized access to document status")
        
    return status_data

@router.get("/list")
def list_documents(tenant_id: str):
    docs = []
    for filename in os.listdir(STATUS_DIR):
        if filename.endswith(".json"):
            with open(os.path.join(STATUS_DIR, filename), "r") as f:
                data = json.load(f)
                if data["tenant_id"] == tenant_id:
                    docs.append(data)
    return docs


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/services/chunker.py
////////////////////////////////////////////////////////////////

def chunk_text(text: str, chunk_size=1200, overlap=200):
    chunks = []
    start = 0
    text_length = len(text)

    while start < text_length:
        end = start + chunk_size
        chunk = text[start:end].strip()

        if chunk:
            chunks.append(chunk)

        start = end - overlap
        if start < 0:
            start = 0

    return chunks


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/services/embeddings.py
////////////////////////////////////////////////////////////////

_model = None

def get_model():
    global _model
    if _model is None:
        from sentence_transformers import SentenceTransformer
        print("Loading SentenceTransformer model...")
        _model = SentenceTransformer("BAAI/bge-small-en")
    return _model

def embed_texts(texts: list[str]):
    model = get_model()
    return model.encode(texts, convert_to_numpy=True).tolist()


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/services/llm.py
////////////////////////////////////////////////////////////////

import requests

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL = "mistral"

def generate_answer(prompt: str) -> str:
    response = requests.post(
        OLLAMA_URL,
        json={
            "model": MODEL,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.2
            }
        },
        timeout=120
    )

    response.raise_for_status()
    return response.json()["response"].strip()


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/services/pdf_loader.py
////////////////////////////////////////////////////////////////

from PyPDF2 import PdfReader

def extract_text_from_pdf(file_path: str) -> str:
    reader = PdfReader(file_path)
    text = ""

    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"

    return text.strip()


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/services/rag.py
////////////////////////////////////////////////////////////////

def build_prompt(context_chunks: list[str], question: str) -> str:
    # Limit context to max 6000 chars to keep token usage low and responses fast
    context = ""
    for chunk in context_chunks:
        if len(context) + len(chunk) > 6000:
            break
        context += chunk + "\n\n"
    
    context = context.strip()

    return f"""
You are a professional customer support assistant for this website.

Rules:
- Answer ONLY using the context below
- Be clear, concise, and professional
- Do not guess or add extra information
- If the answer is not in the context, reply:
  "I couldn’t find this information in the provided documents."

Context:
{context}

Question:
{question}

Answer:
""".strip()


////////////////////////////////////////////////////////////////
 * FILE PATH: ./app/services/vector_store.py
////////////////////////////////////////////////////////////////

_client = None

def get_client():
    global _client
    if _client is None:
        import chromadb
        from chromadb.config import Settings
        print("Initializing ChromaDB client...")
        _client = chromadb.Client(
            Settings(persist_directory="./chroma", anonymized_telemetry=False)
        )
    return _client

def get_collection(tenant_id: str):
    client = get_client()
    return client.get_or_create_collection(name=tenant_id)
